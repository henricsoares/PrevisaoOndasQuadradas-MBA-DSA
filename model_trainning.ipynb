{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregue as bibliotecas necessárias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from _utils import (NeuralNetwork, train_and_validate_with_kfold, train_and_validade,\n",
    "plot_curvas_aprendizado, plot_pesos, test_model_with_new_data, \n",
    "previsao_without_normalization, previsao_with_normalization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Carregando o conjunto de dados\n",
    "### Carregue o conjunto de dados gerado a partir do script dataset_generator.py e os separe em data e target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = {}\n",
    "with open(\"./dataset.json\", \"r\") as arquivo:\n",
    "    dados = json.load(arquivo)\n",
    "\n",
    "data = [(d[\"coords\"]) for d in dados[\"dados\"]]\n",
    "target = [d[\"params\"] for d in dados[\"dados\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize os dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta 'data' para um array bidimensional\n",
    "data_flattened = [sample for series in data for sample in series]\n",
    "\n",
    "# Crie uma instância do MinMaxScaler e ajuste aos dados\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data_flattened)\n",
    "\n",
    "# Normalize os dados\n",
    "data_normalized = [scaler.transform(series) for series in data]\n",
    "\n",
    "scaler.fit(target)\n",
    "\n",
    "# Normalize os rótulos\n",
    "target_normalized = scaler.transform(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separando os dados em treino e teste\n",
    "###  Separe os dados em 20% teste, 80% para treino e validação\n",
    "#### Aqui temos dois tipos de dados: não normalizados e normalizados (com sufixo N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2  # 20% dos dados para teste\n",
    "train_dataN, test_dataN, train_targetN, test_targetN = train_test_split(\n",
    "    data_normalized, target_normalized, test_size=test_size, random_state=42\n",
    ")\n",
    "\n",
    "train_dataN, val_dataN, train_targetN, val_targetN = train_test_split(\n",
    "    train_dataN, train_targetN, test_size=test_size, random_state=42\n",
    ")\n",
    "\n",
    "train_data, test_data, train_target, test_target = train_test_split(\n",
    "    data, target, test_size=test_size, random_state=42\n",
    ")\n",
    "\n",
    "train_data, val_data, train_target, val_target = train_test_split(\n",
    "    train_data, train_target, test_size=test_size, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo a arquitetura da rede neural\n",
    "### Defina a arquitetura da rede neural a ser treinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 1\n",
    "units_fc = [32,]\n",
    "\n",
    "modeloA, modeloB, modeloC = NeuralNetwork(num_layers, units_fc), NeuralNetwork(num_layers, units_fc), NeuralNetwork(num_layers, units_fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo\n",
    "### Treino o modelo com os métodos:\n",
    "#### - train_and_validate\n",
    "#### - train_and_validate_with_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "num_epochs = 25\n",
    "batch_size = 32\n",
    "\n",
    "modeloA, metricsA = train_and_validade(modeloA, train_data, train_target, val_data,\n",
    "                                       val_target, num_epochs, batch_size)\n",
    "modeloB, metricsB = train_and_validade(modeloB, train_dataN, train_targetN, val_dataN,\n",
    "                                       val_targetN, num_epochs, batch_size)\n",
    "modeloC, metricsC = train_and_validate_with_kfold(modeloC, train_dataN, train_targetN,\n",
    "                                       num_epochs, num_folds, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salve o modelo\n",
    "path = \"modeloA.pth\"\n",
    "torch.save(modeloA.state_dict(), path)\n",
    "\n",
    "path = \"modeloB.pth\"\n",
    "torch.save(modeloB.state_dict(), path)\n",
    "\n",
    "path = \"modeloC.pth\"\n",
    "torch.save(modeloC.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curvas de aprendizado para treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_curvas_aprendizado(metricsB, metricsC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribuição dos pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_pesos(modeloC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avalie o modelo com os dados de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_tensor = torch.Tensor(np.array(test_dataN))\n",
    "y_test_tensor = torch.Tensor(np.array(test_targetN))\n",
    "\n",
    "x_test_tensor1 = torch.Tensor(np.array(val_data))\n",
    "y_test_tensor1 = torch.Tensor(np.array(val_target))\n",
    "\n",
    "test_dataset = TensorDataset(x_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset1 = TensorDataset(x_test_tensor1, y_test_tensor1)\n",
    "test_loader1 = DataLoader(test_dataset1, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_lossesA = test_model_with_new_data(modeloA, test_loader1)\n",
    "test_lossesB = test_model_with_new_data(modeloB, test_loader)\n",
    "test_lossesC = test_model_with_new_data(modeloC, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plote a curva de perda durante os testes\n",
    "plt.plot(test_lossesC, marker=\"o\", linestyle=\"-\")\n",
    "plt.xlabel(\"Iteração do Teste\")\n",
    "plt.ylabel(\"Perda do Teste\")\n",
    "plt.title(\"Curva de Perda durante os Testes\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste novos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare visualmente a previsão com o dado orignal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para gerar o gráfico\n",
    "def plot_grafico(linhas, new_data, ax, titulo):\n",
    "    # Defina o tamanho do gráfico\n",
    "    x_min, x_max = 0, 6000\n",
    "    y_min, y_max = 0, 8\n",
    "    dmin, dmax = linhas[2], linhas[3]\n",
    "    tl, th = linhas[0], linhas[1]\n",
    "\n",
    "    x_line = [[x_min, dmin, dmin, dmax, dmax, x_max]]\n",
    "\n",
    "    y_line = [[tl, tl, th, th, tl, tl]]\n",
    "\n",
    "    ax.plot(x_line[0], y_line[0], color=\"red\")\n",
    "\n",
    "    ax.scatter([x[0] for x in new_data], [y[1] for y in new_data], c=\"blue\")\n",
    "\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_title(titulo, loc=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nDados = {}\n",
    "with open(\"./newData.json\", \"r\") as arquivo:\n",
    "    nDados = json.load(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 1, figsize=(6, 18))\n",
    "previsaoA, pontos, params, mseA = previsao_without_normalization(modeloA, nDados)\n",
    "previsaoB, pontos, params, mseB = previsao_with_normalization(modeloC, nDados, target, scaler)\n",
    "# previsaoA, pontos, params, mseA = previsao_with_normalization(modeloC, nDados)\n",
    "# # Converta a previsão para coordenadas no gráfico\n",
    "# scaler.fit(target)\n",
    "# previsaoA = scaler.inverse_transform(previsaoB.detach().numpy())\n",
    "linhasA = previsaoA.tolist()[0]\n",
    "scaler.fit(target)\n",
    "previsao_c = scaler.inverse_transform(previsaoB.detach().numpy())\n",
    "linhasB = previsao_c.tolist()[0]\n",
    "plot_grafico(linhasB, pontos, axs[2], \"C.   Modelo B\")\n",
    "axs[2].text(\n",
    "    0.5,\n",
    "    0.9,\n",
    "    f\"MSE: {mseB:.5f}\",\n",
    "    transform=axs[2].transAxes,\n",
    "    ha=\"center\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plot_grafico(linhasA, pontos, axs[1], \"B.   Modelo A\")\n",
    "axs[1].text(\n",
    "    0.5,\n",
    "    0.9,\n",
    "    f\"MSE: {mseA:.5f}\",\n",
    "    transform=axs[1].transAxes,\n",
    "    ha=\"center\",\n",
    "    fontsize=14,\n",
    ")\n",
    "plot_grafico(params[0], pontos, axs[0], \"A. Rótulos Não Utilizados no Treinamento\")\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=14)\n",
    "    ax.set_title(ax.get_title(), fontsize=14)\n",
    "plt.savefig(\"comparação_modeloAB_original2203.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Converta a previsão para coordenadas no gráfico\n",
    "scaler.fit(target)\n",
    "previsao_c1 = scaler.inverse_transform(previsao1.detach().numpy())\n",
    "linhas1 = previsao_c1.tolist()[0]\n",
    "previsao_c2 = scaler.inverse_transform(previsao2.detach().numpy())\n",
    "linhas2 = previsao_c2.tolist()[0]\n",
    "previsao_c3 = scaler.inverse_transform(previsao3.detach().numpy())\n",
    "linhas3 = previsao_c3.tolist()[0]\n",
    "\n",
    "# Plote os gráficos\n",
    "plot_grafico(linhas1, pontos, axs[0], \"MSE\")\n",
    "plot_grafico(linhas2, pontos, axs[1], \"R²\")\n",
    "plot_grafico(linhas3, pontos, axs[2], \"Ponderada\")\n",
    "\n",
    "oParams = scaler.transform(params)\n",
    "pondParams = previsao3.detach().numpy()\n",
    "r2Params = previsao2.detach().numpy()\n",
    "mseParams = previsao1.detach().numpy()\n",
    "\n",
    "mse1 = calcula_mse(mseParams, oParams)\n",
    "mse2 = calcula_mse(r2Params, oParams)\n",
    "mse3 = calcula_mse(pondParams, oParams)\n",
    "\n",
    "axs[0].text(\n",
    "    0.5, 0.9, f\"MSE: {mse1:.4f}\", transform=axs[0].transAxes, ha=\"center\", fontsize=14\n",
    ")\n",
    "axs[1].text(\n",
    "    0.5, 0.9, f\"MSE: {mse2:.4f}\", transform=axs[1].transAxes, ha=\"center\", fontsize=14\n",
    ")\n",
    "axs[2].text(\n",
    "    0.5, 0.9, f\"MSE: {mse3:.4f}\", transform=axs[2].transAxes, ha=\"center\", fontsize=14\n",
    ")\n",
    "\n",
    "for ax in axs:\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=14)\n",
    "    ax.set_xlabel(ax.get_xlabel(), fontsize=14)\n",
    "    ax.set_ylabel(ax.get_ylabel(), fontsize=14)\n",
    "    ax.set_title(ax.get_title(), fontsize=14)\n",
    "\n",
    "plt.savefig(\"comparação_previsao_mse_r2_ponderada1.png\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
